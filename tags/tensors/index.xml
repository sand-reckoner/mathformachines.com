<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tensors on Math for Machines</title>
    <link>https://mathformachines.com/tags/tensors/</link>
    <description>Recent content in Tensors on Math for Machines</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;Ryan Holbrook 2019</copyright>
    <lastBuildDate>Tue, 05 Feb 2019 12:59:00 -0600</lastBuildDate>
    
	<atom:link href="https://mathformachines.com/tags/tensors/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Tour of Tensors</title>
      <link>https://mathformachines.com/posts/a-tour-of-tensors/</link>
      <pubDate>Tue, 05 Feb 2019 12:59:00 -0600</pubDate>
      
      <guid>https://mathformachines.com/posts/a-tour-of-tensors/</guid>
      <description>&lt;p&gt;Tensors can sometimes have a fearsome reputation. They are at heart, however, no more difficult to define than polynomials. I&amp;rsquo;ve tried in these notes to take a computational focus and to avoid formalism when possible; I haven&amp;rsquo;t assumed any more than what you might encounter in an undergraduate linear algebra course. If you&amp;rsquo;re interested in tensors applied to machine learning, or have wondered why arrays in Tensorflow are called tensors, you might find this useful. I&amp;rsquo;ll do some computations in &lt;a href=&#34;http://www.sagemath.org/&#34;&gt;Sage&lt;/a&gt; and also in &lt;a href=&#34;http://www.numpy.org/&#34;&gt;Numpy&lt;/a&gt; for illustration.&lt;/p&gt;

&lt;h2 id=&#34;abstract-tensors&#34;&gt;Abstract Tensors&lt;/h2&gt;

&lt;p&gt;First, let&amp;rsquo;s take brief look at tensors in the abstract. This is just to give us an idea of what properties they have and how they function. I&amp;rsquo;ll gloss over most of the details of the construction.&lt;/p&gt;

&lt;p&gt;A tensor is a vector. It is an element of a vector space. Being a vector, if we have a basis for the space we can write the tensor as a list of coordinates (or maybe something like a matrix or an array â€“ we&amp;rsquo;ll see how).&lt;/p&gt;

&lt;p&gt;A tensor is a vector in a product vector space. This means that part of it comes from one vector space and part of it comes from another. These parts combine in a way that fits with the usual notions of how products should work. Why would we want these tensors, these products of vectors? It turns out that lots of useful things are tensors. Matrices and linear maps are tensors, and so are determinants and inner products and cross products. Tensors give us power to express many useful ideas.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
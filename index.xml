<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math for Machines</title>
    <link>//mathformachines.com/</link>
    <description>Recent content on Math for Machines</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Feb 2019 12:59:00 -0600</lastBuildDate>
    
	<atom:link href="//mathformachines.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Tour of Tensors</title>
      <link>//mathformachines.com/2019-02-05-a-tour-of-tensors/</link>
      <pubDate>Tue, 05 Feb 2019 12:59:00 -0600</pubDate>
      
      <guid>//mathformachines.com/2019-02-05-a-tour-of-tensors/</guid>
      <description>&lt;p&gt;Here are some notes on tensors, starting from basic linear algebra. I&amp;rsquo;ve tried to take a computational focus and to avoid formalism when possible. If you&amp;rsquo;re interested in tensors applied to machine learning, or have wondered why arrays in Tensorflow are called tensors, you might find this useful. I&amp;rsquo;ll do some computations in &lt;a href=&#34;http://www.sagemath.org/&#34; target=&#34;_blank&#34;&gt;Sage&lt;/a&gt; and also in &lt;a href=&#34;http://www.numpy.org/&#34; target=&#34;_blank&#34;&gt;Numpy&lt;/a&gt; for illustration.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bayesian Topic Modeling</title>
      <link>//mathformachines.com/2019-01-30-bayesian-topic-modeling/</link>
      <pubDate>Wed, 30 Jan 2019 05:57:00 -0600</pubDate>
      
      <guid>//mathformachines.com/2019-01-30-bayesian-topic-modeling/</guid>
      <description>Imagine we have some collection of documents. They could be novels, or tweets, or financial reports&amp;mdash;just any collection of text. We want an algorithm that can discover what they are about, and we would like our algorithm to do it automatically, without any hints. (That is, we want our algorithm to be unsupervised.) We will look at several models that probabilistically assign words to topics using Bayes&amp;rsquo; Theorem. They are all Bayesian Graphical Models.</description>
    </item>
    
  </channel>
</rss>